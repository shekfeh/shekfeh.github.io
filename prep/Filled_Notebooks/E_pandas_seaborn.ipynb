{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gl__1mt1BL4"
      },
      "source": [
        "<div style=\"text-align:center;\">\n",
        "  <img src=\"https://github.com/MolSSI-Education/iqb-2025/blob/main/images/molssi_main_outline.png?raw=true\\\" style=\"display: block; margin: 0 auto; max-height:200px;\">\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "Examining and Visualizing Data\n",
        "=============================\n",
        "\n",
        "<strong>Author(s):</strong> Jessica A. Nash, The Molecular Sciences Software Institute\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<h2>Overview</h2>\n",
        "\n",
        "<strong>Questions:</strong>\n",
        "\n",
        "* How can I use pandas to process data?\n",
        "\n",
        "* How can I visualize relationships between different parts of my data?\n",
        "\n",
        "<strong>Objectives:</strong>\n",
        "\n",
        "* Use pandas and seaborn to load and explore data\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNVJomRi1BL6"
      },
      "source": [
        "[Pandas](https://pandas.pydata.org/docs/) is a Python library used for data analysis and manipulation. Within the world of data science, it is a ubiquitous and widely used library. If you are learning how to analyze data in Python, it will be almost impossible to avoid pandas.\n",
        "\n",
        "The central data structure of pandas is called a DataFrame. Pandas DataFrames work very closely with NumPy arrays and Pandas dataframes are specifically for data which is two dimensional (rows and columns). NumPy arrays, while similar in some ways, can work with higher dimensional data.\n",
        "\n",
        "Pandas is very powerful. In this session, we'll be learning how to access information in pandas dataframes and how to do some basic manipulation and analysis. We are going to be looking at a dataset which gives information about the elements in the periodic table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F72xtliv1KkY"
      },
      "outputs": [],
      "source": [
        "!pip install pandas seaborn matplotlib rdkit # NOTE: You can install multiple libraries with one command."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZV-aEQ13TZS"
      },
      "source": [
        "## Pandas Dataframes\n",
        "\n",
        "In this notebook, we will load from a comma separate file (.csv - kind of a simplified version of a spreadsheet) into a pandas dataframe, which is a two-dimensional array of data in rows and columns. In this notebooks we will take advantage of some of the features that are native to pandas dataframes for data analysis and plotting.\n",
        "\n",
        "The code in the cell below uses `urlretrieve` from the `urllib.request` library to assign a csv file from GitHub to the variable `filename` and then uses pandas to create a dataframe based on the csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7KUqqPf1BL6"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlretrieve\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/MolSSI-Education/molssicheminfo/refs/heads/master/data/PubChemElements_all.csv\"\n",
        "filename = \"PubChemElements_all.csv\"\n",
        "urlretrieve(url, filename)\n",
        "\n",
        "df = pd.read_csv(filename)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHnp9uqX1BL7"
      },
      "source": [
        "## Examining Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE8N3exr1BL7"
      },
      "source": [
        "Initially when loading data in, and also at certain points as we're working with it, we'll want to see what our dataframe looks like. You can see a preview of your dataframe using the `.head` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJIaWKHf1BL7"
      },
      "outputs": [],
      "source": [
        "# The .head command will display the first five rows of the dataframe.\n",
        "\n",
        "df.head()\n",
        "\n",
        "# In Google CoLab, you can click the variable record on the left {x} to learn more about this dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpDhoZea1BL7"
      },
      "source": [
        "The `.info` function will give information about the columns and the data type of those columns. The data type will become very important later as we work with data more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3eBcLoG1BL7",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5valH56E1BL8"
      },
      "source": [
        "For this dataframe, we see that the first column, `AtomicNumber` has the data type of `int64`. Here, `int` means `integer` and `64` means `64 bit`.  The `64 bit` refers to the amount of computer memory the variable can occupy. It won't really be important for us. Similarly, `float64` means `64 bit floating point`. These are decimal numbers.\n",
        "\n",
        "The other column names which read `object` are not numeric. They might be strings or they might be something else. We'll discuss more later.\n",
        "\n",
        "The `describe` function can be used on a dataframe to quickly see statistics about columns with numerical data. If you look at the columns that statistics are computed for and compare to the data type shown from `info`, you will see that we only get statistics for columns which had `int64` or `float64` data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RsOeMAv1BL8"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1M6VIS21BL8"
      },
      "source": [
        "This information is extremely useful for understanding the data. We can also easily visualize the distribution of each column using Pandas's ``hist`` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "padZJvd91BL8"
      },
      "outputs": [],
      "source": [
        "df.hist(figsize=(8, 8), edgecolor=\"black\", grid=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4gGStV81BL8"
      },
      "source": [
        "## Accessing Data\n",
        "\n",
        "Pandas dataframes have names for rows (called the \"index\" in Pandas) and columns.\n",
        "\n",
        "Pandas dataframes have rows and columns, you can see how many rows and columns using `.shape`. This will return the shape as `(num_rows, num_columns)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTjUSi9s1BL8"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQNFLJk21BL8"
      },
      "source": [
        "There are a few methods for accessing information in a Pandas dataframe, but the one that will be most important in this workshop is selecting particular columns of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0GzycHy1BL9"
      },
      "outputs": [],
      "source": [
        "# You can select one column by putting the column header in the square brackets.\n",
        "# The header is a string, so it must be in quotes.\n",
        "\n",
        "df[\"AtomicNumber\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODTdsHzj1BL9"
      },
      "outputs": [],
      "source": [
        "# To select multiple columns, put list in brackets\n",
        "\n",
        "df[[\"Symbol\", \"ElectronConfiguration\"]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpSayfPS1BL9"
      },
      "source": [
        "## Performing calculations with pandas: No more `for` loops!\n",
        "\n",
        "Both pandas and NumPy dataframes have the convenient feature that they can do element-wise operations and use something called `broadcasting`. This means that if you are doing something like subtracting a number, multiplying, etc to a column or dataframe of information, it can be done all at once instead of with a `for` loop. Consider if we wanted to calculate the melting point in degrees celsius for all of the elements.\n",
        "\n",
        "Instead of writing a `for` loop that does this, we can just write the following code. This will return a pandas Series (one dimensional dataframe)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSaWkwpb1BL9"
      },
      "outputs": [],
      "source": [
        "df['MeltingPoint'] - 273.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uQx_WLb1BL9"
      },
      "source": [
        "We could do this one two columns as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wrRpOL41BL9"
      },
      "outputs": [],
      "source": [
        "df[['MeltingPoint', 'BoilingPoint']] - 273.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQyz3nrz1BL9"
      },
      "source": [
        "We can save these in new dataframe columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkynyMMS1BL9"
      },
      "outputs": [],
      "source": [
        "# TO DO: Look for the new columns on the right hand side of the dataframe\n",
        "\n",
        "df[[\"MeltingPointC\", \"BoilingPointC\"]] = df[['MeltingPoint', 'BoilingPoint']] - 273.15\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJqiEad11BL9"
      },
      "source": [
        "### The `.apply` method\n",
        "\n",
        "The `.apply` method in pandas is used to apply a function along a row or column of a dataframe.\n",
        "This is useful when you have a custom function that you need to use on every value in a column, but there is not a NumPy or Pandas function for it.\n",
        "\n",
        "For example, we could apply the `len` function to our `Name` column to get the number of letters in the name for each element."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKzShBBv1BL-"
      },
      "outputs": [],
      "source": [
        "# Number of letters in name of the element -\n",
        "\n",
        "df[\"Name\"].apply(len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_kPq_OQ1BL-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<strong>The .apply function</strong>\n",
        "\n",
        "Notice that when we use `.apply`, we write the <strong>name</strong> of the function we want to apply,\n",
        "but we do not <strong>call</strong> the function.\n",
        "If we were to call the `len` function, we would use parentheses `()` with an argument.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzV4auDh1BL-"
      },
      "source": [
        "## Using RDKit Functions with Pandas DataFrames\n",
        "For an example more related to our work with RDKit, let's add some additional atomic data.\n",
        "RDKit has the ability to get information about atoms.\n",
        "We can create a periodic table with `Chem.GetPeriodicTable`, then use associated functions to get information about atoms to add more information to our existing pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qcsRNRz1BL-"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "\n",
        "# Initialize the periodic table\n",
        "periodic_table = Chem.GetPeriodicTable()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCrZ0fUd1BL-"
      },
      "source": [
        "After we have a periodic table, we can apply functions from the periodic table to the atoms in our dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPRUFOa-1BL-"
      },
      "outputs": [],
      "source": [
        "df[\"NOuter\"] = df[\"Symbol\"].apply(periodic_table.GetNOuterElecs)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVyJsCUL1BL-"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h3>Exercise</h3>\n",
        "\n",
        "Use the `tab` key on your periodic table object to check for other values you can calculate for atoms.\n",
        "Pick one to add to your periodic table dataset.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUW7mA3p1BL-"
      },
      "outputs": [],
      "source": [
        "# TO DO: Find a method that will give you the default valence for an element\n",
        "\n",
        "df[\"Default_Valence\"] = df[\"Symbol\"].apply(periodic_table.GetDefaultValence)\n",
        "\n",
        "# The df.iloc command lists the contents of specific rows in the dataframe\n",
        "\n",
        "df.iloc[21:31]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxG6533i1BL_"
      },
      "source": [
        "We can save a CSV file with our newly calculated values using the `to_csv` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHVoMLIz1BL_"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"periodic_data_processed.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9IUuGGp1BL_"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "Visualizing data helps in understanding relationships and patterns that might not be apparent from raw data. Here, we will use Seaborn, a statistical visualization library, to create plots from our periodic table dataset. Seaborn is built on top of matplotlib, so if we would like to adjust any of the plots seaborn makes, we can do that through the Matplotlib interface we've used before.\n",
        "\n",
        "We will start with a bar plot to show the ionization energy of elements across different group blocks:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHvxbNcV1BL_"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ3UM43P1BL_"
      },
      "outputs": [],
      "source": [
        "sns.catplot(data=df, x=\"NOuter\", y=\"IonizationEnergy\", kind=\"bar\")\n",
        "# Rotate x-axis labels\n",
        "plt.xticks(rotation=45, ha='right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMgszpBj1BL_"
      },
      "source": [
        "The plot above shows us periodic trends that we learned about in introductory chemistry. The two highest ionization energy categories correspond to elements with 2 valence electrons and 8 valence electrons, representing filled shells.\n",
        "\n",
        "Seaborn can also allow us to easily create scatter plots to visualize relationships between continuous variables. For example, we can create a scatter plot to show the relationship between ionization energy and atomic radius:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2XGYxiH1BME"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(data=df, x=\"AtomicRadius\", y=\"Electronegativity\", hue=\"GroupBlock\")\n",
        "plt.title('Electronegativity vs. Atomic Radius')\n",
        "plt.xlabel('Atomic Radius')\n",
        "plt.ylabel('Electronegativity')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufsnV5FQ1BME"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h3>Exercise</h3>\n",
        "\n",
        "Create a few other categorical plots to observe periodic trends:\n",
        "\n",
        "1. Electronegativity vs. Group Block as a bar plot.\n",
        "\n",
        "2. Melting Point vs. Group Block as a bar plot.\n",
        "\n",
        "3. Ionization Energy vs. Atomic Number as a scatter plot colored by GroupBlock.\n",
        "   \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TTmY-SS1BME"
      },
      "outputs": [],
      "source": [
        "# TO DO: For the x and y values, remember to put the dataframe column title in quotes, but not square brackets\n",
        "\n",
        "sns.barplot(data=df, x=\"GroupBlock\", y=\"Electronegativity\")\n",
        "plt.title(\"Electronegativity vs. Group Block\")\n",
        "plt.xlabel(\"Group Block\")\n",
        "plt.ylabel(\"Electronegativity\")\n",
        "plt.xticks(rotation=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCIw2xAh1BME"
      },
      "outputs": [],
      "source": [
        "# TO DO: Remember to put the dataframe column title in quotes, but not square brackets\n",
        "\n",
        "sns.barplot(data=df, x=\"GroupBlock\", y=\"MeltingPoint\")\n",
        "plt.title(\"Melting Point vs. Group Block\")\n",
        "plt.xlabel(\"Group Block\")\n",
        "plt.ylabel(\"Melting Point\")\n",
        "plt.xticks(rotation=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK-cP-bc1BMF"
      },
      "outputs": [],
      "source": [
        "# TO DO: Remember to put the dataframe column title in quotes, but not square brackets\n",
        "\n",
        "sns.scatterplot(data=df, x=\"GroupBlock\", y=\"IonizationEnergy\", hue=\"GroupBlock\")\n",
        "plt.title('Melting Point vs. Atomic Number')\n",
        "plt.xlabel('Atomic Number')\n",
        "plt.ylabel('Melting Point')\n",
        "plt.xticks(rotation=45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9QADUad1BMF"
      },
      "source": [
        "### Visualizing Correlation\n",
        "\n",
        "A common way to visualize relationships between different categories of data categories is with a correlation plot.\n",
        "The correlation matrix provides insights into the relationships between the variables. A correlation value close to 1 indicates a strong positive relationship, while a correlation value close to -1 indicates a strong negative relationship. A correlation value close to 0 indicates no relationship between the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dbZX9Yc1BMF"
      },
      "outputs": [],
      "source": [
        "# Calculate the correlation matrix\n",
        "\n",
        "corr = df.corr(numeric_only=True)\n",
        "corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhVE4b_D1BMF"
      },
      "source": [
        "Seaborn can be used to create a heatmap to allow easier examination of the correlation of different variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7urDyWr1BMF"
      },
      "outputs": [],
      "source": [
        "# Create a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCsmiHY01BMF"
      },
      "source": [
        "The heatmap uses a \"coolwarm\" color scheme where red indicates positive correlation and blue indicates negative correlation between variables. Strongly correlated pairs are represented by darker shades of red, while strongly inversely correlated pairs are represented by darker shades of blue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIArXkd41BMF"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h3>Final Challenge</h3>\n",
        "\n",
        "For this challenge, you will retrieve a file called `amino_acids.txt` that contains SMILES for the 20 naturally occurring amino acids. Your task for the final challenge of today is to combine skills and concepts you have learned today to build a dataframe for molecules and write a file. Your goal is to create a comma-separated value file with columns `SMILES`, `num_heavy` (number of heavy atoms), `molecular_weight`, and one other molecular descriptor of your choice for the molecules in the file.\n",
        "\n",
        "For this task, you will need to complete the following steps. The first three steps are already completed.\n",
        "\n",
        "1. Retrieve the file amino_acids.txt.\n",
        "1. Read the data in the file and place the SMILES strings in a list.\n",
        "1. Create a pandas dataframe, aadf, with the SMILES string as the first column.\n",
        "1. Use the .apply function to add a new column to aadf that contains an RDKit mol object for each of the SMILES strings.\n",
        "1. Use the .apply function to then add a column with the number of heavy atoms, a column with the molecular weight and a column with one other molecular descriptor of your choice for each molecule in aadf.\n",
        "1. Save your file as `data/amino_acids_processed.csv`.\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqve_OjC1BMF"
      },
      "source": [
        "### Read SMILES from a text file\n",
        "The SMILES strings are contained in the file `amino_acid.txt` on GitHub. In the following cells, you will follow the six steps listed above to complete the challenge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ujrXpeB1BMG"
      },
      "outputs": [],
      "source": [
        "# You will start by importing all of the libraries that you need.\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "import pandas as pd\n",
        "from rdkit.Chem import PandasTools\n",
        "\n",
        "# Ensure molecules are rendered as 2D images in the notebook\n",
        "\n",
        "PandasTools.RenderImagesInAllDataFrames(images=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYBJIN5w3fPi"
      },
      "outputs": [],
      "source": [
        "# Step 1. Retrieve the file amino_acids.txt from GitHub.\n",
        "\n",
        "url = (\"https://raw.githubusercontent.com/MolSSI-Education/molssicheminfo/refs/heads/master/data/amino_acids.txt\")\n",
        "aa_file = \"amino_acids.txt\"\n",
        "urlretrieve(url, aa_file) # checking to make sure it worked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QA2YrDGV1BMG"
      },
      "outputs": [],
      "source": [
        "# Step 2. Read the data in the file and place the SMILES strings in a list.\n",
        "\n",
        "with open(aa_file, \"r\") as outfile:\n",
        "    aasmiles = outfile.readlines()\n",
        "\n",
        "aasmiles_strip = []\n",
        "for smiles in aasmiles:\n",
        "    smiles = smiles.strip()         # strip removes any spaces before or after a string on a line\n",
        "    aasmiles_strip.append(smiles)   # append adds each string to the list, aasmiles_strip\n",
        "\n",
        "print(aasmiles_strip)               # just to print out your list\n",
        "\n",
        "# Step 3. Create a pandas dataframe, aadf, with the SMILES string as the first column.\n",
        "\n",
        "aadf = pd.DataFrame({\"SMILES\": aasmiles_strip})\n",
        "\n",
        "aadf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbb47-d51BMG"
      },
      "source": [
        "### Make an RDKit molecule for each SMILES\n",
        "I did this before. This time, I'll add the SMILES string to the dataframe first, then use the apply function to create the RDKit molecules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bgi3HQaP1BMG"
      },
      "outputs": [],
      "source": [
        "# Step 4. Use the .apply function to add a Molecule column to aadf that\n",
        "# contains an RDKit mol object for each of the SMILES strings.\n",
        "\n",
        "aadf['Molecule'] = aadf['SMILES'].apply(Chem.MolFromSmiles)\n",
        "aadf\n",
        "\n",
        "# NOTE: The PandasTools.RenderImagesInAllDataFrames(images=True) command executed above\n",
        "# means that we will see 2D images of the molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHfZ3YDhNgbQ"
      },
      "outputs": [],
      "source": [
        "# Step 5. Use the .apply function to then add a column with the number of heavy atoms, a column with\n",
        "# the molecular weight and a column with one other molecular descriptor of your choice for each molecule in aadf.\n",
        "\n",
        "aadf['HeavyAtoms'] = aadf['Molecule'].apply(Descriptors.HeavyAtomCount)\n",
        "aadf['MolWt'] = aadf['Molecule'].apply(Descriptors.MolWt)\n",
        "aadf['H_Bond_Donors'] = aadf['Molecule'].apply(Descriptors.NumHDonors)\n",
        "aadf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjuP7LKJ1BMG"
      },
      "outputs": [],
      "source": [
        "# Step 6. Save your file as `data/amino_acids_processed.csv`.\n",
        "\n",
        "outputfile = ('amino_acids_processed.csv')\n",
        "aadf.to_csv(outputfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKdmd8V-1BMH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}